{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad9a8981",
   "metadata": {},
   "source": [
    "## Reference Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db01f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=o-pZk5R0TZg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89113334",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92051dee",
   "metadata": {},
   "source": [
    "## Import the data, as well as split into a smaller/larger dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec5cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source code: https://github.com/amazon-science/esci-data/blob/main/README.md\n",
    "\n",
    "df_examples = pd.read_parquet('shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('shopping_queries_dataset_products.parquet')\n",
    "df_sources = pd.read_csv(\"shopping_queries_dataset_sources.csv\")\n",
    "\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")\n",
    "\n",
    "# Smaller dataset: filter to U.S. products\n",
    "df_task_1 = df[\n",
    "    (df[\"small_version\"] == 1) &\n",
    "    (df[\"product_locale\"] == \"us\") &\n",
    "    (df[\"product_title\"].notnull())\n",
    "]\n",
    "\n",
    "# Task 2: larger dataset\n",
    "df_task_2 = df_examples_products[df_examples_products[\"large_version\"] == 1]\n",
    "df_task_2_train = df_task_2[df_task_2[\"split\"] == \"train\"]\n",
    "df_task_2_test = df_task_2[df_task_2[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e6f615",
   "metadata": {},
   "source": [
    "## Initial Model: Smaller sample set, only looking at exact matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_1 = df_task_1[\n",
    "    (df_task_1[\"split\"] == \"train\")\n",
    "]\n",
    "df_task_1 = df_task_1[df_task_1['esci_label'] == 'E']\n",
    "\n",
    "sample_df = df_task_1.copy()\n",
    "queries = sample_df['query'].values\n",
    "products = sample_df['product_title'].values\n",
    "\n",
    "# Vectorize Queries and Products\n",
    "vectorizer = TfidfVectorizer()\n",
    "query_vecs = vectorizer.fit_transform(queries)\n",
    "product_vecs = vectorizer.transform(products)  # Use same vocab\n",
    "\n",
    "# Score & Recommend \n",
    "for i, query in enumerate(queries):\n",
    "    scores = cosine_similarity(query_vecs[i], product_vecs).flatten()\n",
    "    ranked_indices = scores.argsort()[::-1]\n",
    "    print(f\"\\nTop matches for: '{query}'\")\n",
    "    for idx in ranked_indices[:3]:\n",
    "        print(f\"- {products[idx]} (score: {scores[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c115f6",
   "metadata": {},
   "source": [
    "## Incorporate Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02935d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Smaller Sample + Combine Product Metadata\n",
    "sample_df = df_task_1.sample(n=20, random_state=42).copy()\n",
    "sample_df['full_product_text'] = (\n",
    "    sample_df['product_title'].fillna('') + ' ' +\n",
    "    sample_df['product_description'].fillna('') + ' ' +\n",
    "    sample_df['product_brand'].fillna('')  + ' ' + train_df['product_bullet_point'].fillna('')\n",
    ")\n",
    "\n",
    "queries = sample_df['query'].values\n",
    "products = sample_df['full_product_text'].values\n",
    "\n",
    "# Use SentenceTransformer for Semantic Embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "query_vecs = model.encode(queries, convert_to_tensor=True)\n",
    "product_vecs = model.encode(products, convert_to_tensor=True)\n",
    "\n",
    "# Score, Normalize, Recommend\n",
    "for i in range(len(queries)):\n",
    "    scores = cosine_similarity(query_vecs[i].cpu().numpy().reshape(1, -1),\n",
    "                               product_vecs.cpu().numpy()).flatten()\n",
    "    # Normalize scores between 0 and 1\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "\n",
    "    ranked_indices = scores.argsort()[::-1]\n",
    "    print(f\"\\nTop matches for: '{queries[i]}'\")\n",
    "    for idx in ranked_indices[:3]:\n",
    "        print(f\"- {sample_df.iloc[idx]['product_title']} (score: {scores[idx]:.4f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546db8ab",
   "metadata": {},
   "source": [
    "## Incorporate training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833eaabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_task_1_train.sample(n=30, random_state=42).copy()\n",
    "train_df['full_product_text'] = (\n",
    "    train_df['product_title'].fillna('') + ' ' +\n",
    "    train_df['product_description'].fillna('') + ' ' +\n",
    "    train_df['product_brand'].fillna('') + ' ' + train_df['product_bullet_point'].fillna('')\n",
    ")\n",
    "train_products = train_df['full_product_text'].values\n",
    "train_titles = train_df['product_title'].values  # for display\n",
    "\n",
    "# Prepare Test Queries \n",
    "test_df = df_task_1_test.sample(n=5, random_state=24).copy()\n",
    "test_queries = test_df['query'].values\n",
    "\n",
    "# Embeddings \n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "product_vecs = model.encode(train_products, convert_to_tensor=True)\n",
    "query_vecs = model.encode(test_queries, convert_to_tensor=True)\n",
    "\n",
    "# Recommend Products for Each Query\n",
    "for i, query in enumerate(test_queries):\n",
    "    scores = cosine_similarity(\n",
    "        query_vecs[i].cpu().numpy().reshape(1, -1),\n",
    "        product_vecs.cpu().numpy()\n",
    "    ).flatten()\n",
    "\n",
    "    # Normalize scores between 0 and 1\n",
    "    scores = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)\n",
    "    ranked_indices = scores.argsort()[::-1]\n",
    "\n",
    "    print(f\"\\nTop matches for test query: '{query}'\")\n",
    "    for idx in ranked_indices[:3]:\n",
    "        print(f\"- {train_titles[idx]} (score: {scores[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84031829",
   "metadata": {},
   "source": [
    "## Trying to use Recall and MRR (This doesn't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51021787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Filter for US, Exact Matches, Titles Present ===\n",
    "df_task_1 = df[\n",
    "    (df[\"small_version\"] == 1) &\n",
    "    (df[\"product_locale\"] == \"us\") &\n",
    "    (df[\"product_title\"].notnull()) &\n",
    "    (df[\"esci_label\"] == \"E\")\n",
    "]\n",
    "\n",
    "# === Full Train and Test Sets ===\n",
    "df_train = df_task_1[df_task_1[\"split\"] == \"train\"].copy()\n",
    "df_test = df_task_1[df_task_1[\"split\"] == \"test\"].sample(n=20, random_state=24).copy()\n",
    "\n",
    "# === Build full product metadata ===\n",
    "df_train['full_product_text'] = (\n",
    "    df_train['product_title'].fillna('') + ' ' +\n",
    "    df_train['product_description'].fillna('') + ' ' +\n",
    "    df_train['product_brand'].fillna('')\n",
    ")\n",
    "\n",
    "# === SentenceTransformer Embeddings ===\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "product_vecs = model.encode(df_train['full_product_text'].values, convert_to_tensor=True)\n",
    "product_ids = df_train['product_id'].values\n",
    "\n",
    "query_vecs = model.encode(df_test['query'].values, convert_to_tensor=True)\n",
    "true_ids = df_test['product_id'].values\n",
    "\n",
    "# === Evaluate Recall@3 and MRR@3 ===\n",
    "k = 3\n",
    "recall_hits = 0\n",
    "reciprocal_ranks = []\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    scores = cosine_similarity(\n",
    "        query_vecs[i].cpu().numpy().reshape(1, -1),\n",
    "        product_vecs.cpu().numpy()\n",
    "    ).flatten()\n",
    "\n",
    "    ranked_indices = scores.argsort()[::-1][:k]\n",
    "    retrieved_ids = product_ids[ranked_indices]\n",
    "\n",
    "    print(f\"\\nüîç Query: {df_test.iloc[i]['query']}\")\n",
    "    print(\"Top retrieved product IDs:\", list(retrieved_ids))\n",
    "    print(\"True product ID:\", true_ids[i])\n",
    "\n",
    "    if true_ids[i] in retrieved_ids:\n",
    "        recall_hits += 1\n",
    "        rank = list(retrieved_ids).index(true_ids[i]) + 1\n",
    "        reciprocal_ranks.append(1.0 / rank)\n",
    "    else:\n",
    "        reciprocal_ranks.append(0.0)\n",
    "\n",
    "recall_at_k = recall_hits / len(df_test)\n",
    "mrr_at_k = np.mean(reciprocal_ranks)\n",
    "\n",
    "print(f\"\\n‚ú® Evaluation Results (Full Train Set):\")\n",
    "print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "print(f\"MRR@{k}:    {mrr_at_k:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84ce28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
